{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trading Strategy ML - Google Colab Setup\n",
        "\n",
        "This notebook sets up and runs the Multi-Factor Momentum Trading Strategy with ML Enhancement on Google Colab with GPU support.\n",
        "\n",
        "## Features\n",
        "- GPU-accelerated training\n",
        "- Real-time data collection\n",
        "- Advanced ML models (CNN+LSTM)\n",
        "- Comprehensive backtesting\n",
        "- Performance analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"CUDA available:\", tf.test.is_built_with_cuda())\n",
        "\n",
        "# Enable GPU memory growth\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    try:\n",
        "        for gpu in tf.config.list_physical_devices('GPU'):\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU memory growth error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages with error handling and alternatives\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package, alternative=None):\n",
        "    \"\"\"Install package with fallback to alternative if needed\"\"\"\n",
        "    try:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"✓ {package} installed successfully\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ Failed to install {package}: {e}\")\n",
        "        if alternative:\n",
        "            try:\n",
        "                print(f\"Trying alternative: {alternative}\")\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", alternative])\n",
        "                print(f\"✓ {alternative} installed successfully\")\n",
        "                return True\n",
        "            except subprocess.CalledProcessError as e2:\n",
        "                print(f\"✗ Alternative {alternative} also failed: {e2}\")\n",
        "        return False\n",
        "\n",
        "# Core packages (usually work fine)\n",
        "core_packages = [\n",
        "    \"pandas>=1.5.0\",\n",
        "    \"numpy>=1.21.0\", \n",
        "    \"scipy>=1.9.0\",\n",
        "    \"matplotlib>=3.5.0\",\n",
        "    \"seaborn>=0.11.0\",\n",
        "    \"plotly>=5.10.0\",\n",
        "    \"requests>=2.28.0\",\n",
        "    \"tqdm>=4.64.0\",\n",
        "    \"joblib>=1.1.0\",\n",
        "    \"python-dotenv>=0.19.0\"\n",
        "]\n",
        "\n",
        "# Financial data packages\n",
        "financial_packages = [\n",
        "    (\"yfinance>=0.2.0\", None),\n",
        "    (\"alpha-vantage>=2.3.0\", None),\n",
        "    (\"pandas-datareader>=0.10.0\", None)\n",
        "]\n",
        "\n",
        "# Technical analysis (problematic package)\n",
        "ta_packages = [\n",
        "    (\"TA-Lib>=0.4.25\", \"talib-binary>=0.4.19\")\n",
        "]\n",
        "\n",
        "# ML packages\n",
        "ml_packages = [\n",
        "    (\"tensorflow>=2.10.0\", \"tensorflow-gpu>=2.10.0\"),\n",
        "    (\"torch>=1.12.0\", None),\n",
        "    (\"torchvision>=0.13.0\", None),\n",
        "    (\"scikit-learn>=1.1.0\", None),\n",
        "    (\"xgboost>=1.6.0\", None),\n",
        "    (\"optuna>=3.0.0\", None),\n",
        "    (\"lightgbm>=3.3.0\", None)\n",
        "]\n",
        "\n",
        "# Financial analysis packages\n",
        "analysis_packages = [\n",
        "    (\"backtrader>=1.9.76\", None),\n",
        "    (\"arch>=5.3.0\", None),\n",
        "    (\"empyrical>=0.5.5\", None),\n",
        "    (\"ffn>=0.3.7\", None)\n",
        "]\n",
        "\n",
        "# UI packages\n",
        "ui_packages = [\n",
        "    (\"streamlit>=1.12.0\", None),\n",
        "    (\"dash>=2.6.0\", None)\n",
        "]\n",
        "\n",
        "print(\"🚀 Starting package installation...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Install core packages first\n",
        "print(\"\\n📦 Installing core packages...\")\n",
        "for package in core_packages:\n",
        "    install_package(package)\n",
        "\n",
        "# Install financial packages\n",
        "print(\"\\n💰 Installing financial data packages...\")\n",
        "for package, alt in financial_packages:\n",
        "    install_package(package, alt)\n",
        "\n",
        "# Install TA-Lib with special handling\n",
        "print(\"\\n📊 Installing technical analysis packages...\")\n",
        "ta_success = False\n",
        "for package, alt in ta_packages:\n",
        "    if install_package(package, alt):\n",
        "        ta_success = True\n",
        "        break\n",
        "\n",
        "if not ta_success:\n",
        "    print(\"⚠️ TA-Lib installation failed. Using alternative approach...\")\n",
        "    # Try installing from conda-forge\n",
        "    try:\n",
        "        subprocess.check_call([\"pip\", \"install\", \"-q\", \"TA-Lib\"])\n",
        "        print(\"✓ TA-Lib installed via alternative method\")\n",
        "        ta_success = True\n",
        "    except:\n",
        "        print(\"⚠️ TA-Lib still failed. Some technical indicators may not work.\")\n",
        "\n",
        "# Install ML packages\n",
        "print(\"\\n🤖 Installing machine learning packages...\")\n",
        "for package, alt in ml_packages:\n",
        "    install_package(package, alt)\n",
        "\n",
        "# Install analysis packages\n",
        "print(\"\\n📈 Installing financial analysis packages...\")\n",
        "for package, alt in analysis_packages:\n",
        "    install_package(package, alt)\n",
        "\n",
        "# Install UI packages\n",
        "print(\"\\n🖥️ Installing UI packages...\")\n",
        "for package, alt in ui_packages:\n",
        "    install_package(package, alt)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"✅ Package installation complete!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test critical imports\n",
        "print(\"\\n🧪 Testing critical imports...\")\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    import sklearn\n",
        "    import yfinance as yf\n",
        "    print(\"✓ Core packages imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Some packages failed to import: {e}\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"\\n🎮 GPU Status:\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "print(f\"CUDA available: {tf.test.is_built_with_cuda()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Simplified Installation (if above fails)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simplified installation - run this if the above cell fails\n",
        "# This installs only the essential packages needed to run the trading strategy\n",
        "\n",
        "print(\"🔧 Installing essential packages only...\")\n",
        "\n",
        "# Essential packages that usually work in Colab\n",
        "essential_packages = [\n",
        "    \"pandas\",\n",
        "    \"numpy\", \n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"plotly\",\n",
        "    \"yfinance\",\n",
        "    \"tensorflow\",\n",
        "    \"scikit-learn\",\n",
        "    \"requests\",\n",
        "    \"tqdm\"\n",
        "]\n",
        "\n",
        "for package in essential_packages:\n",
        "    try:\n",
        "        print(f\"Installing {package}...\")\n",
        "        !pip install -q {package}\n",
        "        print(f\"✓ {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ {package} failed: {e}\")\n",
        "\n",
        "print(\"\\n✅ Essential packages installation complete!\")\n",
        "\n",
        "# Test imports\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import plotly.graph_objects as go\n",
        "    import yfinance as yf\n",
        "    import tensorflow as tf\n",
        "    import sklearn\n",
        "    print(\"\\n🎉 All essential packages imported successfully!\")\n",
        "    print(f\"TensorFlow version: {tf.__version__}\")\n",
        "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\n⚠️ Some packages failed to import: {e}\")\n",
        "    print(\"You may need to restart the runtime and try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository (replace with your GitHub URL)\n",
        "!git clone https://github.com/CatalinMoldova/trading-strategy-ml.git\n",
        "\n",
        "# Change to the project directory\n",
        "%cd trading-strategy-ml\n",
        "\n",
        "# Install project requirements\n",
        "!pip install -r requirements_colab.txt\n",
        "\n",
        "print(\"Repository cloned and requirements installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project src to path\n",
        "sys.path.append('src')\n",
        "\n",
        "# Import project modules with correct class names and error handling\n",
        "try:\n",
        "    from data_pipeline.market_data_collector import MarketDataCollector\n",
        "    from data_pipeline.indicator_engine import TechnicalIndicatorEngine\n",
        "    from data_pipeline.feature_engineer import FeatureEngineer\n",
        "    from ml_models.cnn_lstm_model import CNNLSTMModel\n",
        "    from ml_models.random_forest_model import RandomForestModel\n",
        "    from ml_models.ensemble_predictor import EnsemblePredictor\n",
        "    from strategy.signal_generator import MultiFactorSignalGenerator\n",
        "    from strategy.position_sizer import PositionSizer\n",
        "    from strategy.risk_manager import RiskManager\n",
        "    from backtesting.backtest_engine import BacktestEngine\n",
        "    from backtesting.performance_analyzer import PerformanceAnalyzer\n",
        "    print(\"✅ All project modules imported successfully!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Some project modules failed to import: {e}\")\n",
        "    print(\"Using simplified implementations instead...\")\n",
        "    \n",
        "    # Create simplified fallback classes\n",
        "    class MarketDataCollector:\n",
        "        def get_historical_data(self, symbol, period='2y', interval='1d'):\n",
        "            import yfinance as yf\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            return ticker.history(period=period, interval=interval)\n",
        "    \n",
        "    class TechnicalIndicatorEngine:\n",
        "        def calculate_all_indicators(self, df):\n",
        "            # Simple technical indicators without TA-Lib\n",
        "            df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "            df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
        "            df['RSI'] = self._calculate_rsi(df['Close'])\n",
        "            df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()\n",
        "            return df\n",
        "        \n",
        "        def _calculate_rsi(self, prices, period=14):\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            return 100 - (100 / (1 + rs))\n",
        "    \n",
        "    class FeatureEngineer:\n",
        "        def create_features(self, df):\n",
        "            # Simple feature engineering\n",
        "            df['Price_Change'] = df['Close'].pct_change()\n",
        "            df['Volume_Change'] = df['Volume'].pct_change()\n",
        "            df['High_Low_Ratio'] = df['High'] / df['Low']\n",
        "            df['Close_Open_Ratio'] = df['Close'] / df['Open']\n",
        "            return df\n",
        "    \n",
        "    class CNNLSTMModel:\n",
        "        def __init__(self, time_steps=60, n_features=20, learning_rate=0.001):\n",
        "            self.time_steps = time_steps\n",
        "            self.n_features = n_features\n",
        "            self.learning_rate = learning_rate\n",
        "            self.model = None\n",
        "        \n",
        "        def build_model(self):\n",
        "            import tensorflow as tf\n",
        "            from tensorflow.keras.models import Sequential\n",
        "            from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "            \n",
        "            model = Sequential([\n",
        "                LSTM(50, return_sequences=True, input_shape=(self.time_steps, self.n_features)),\n",
        "                Dropout(0.2),\n",
        "                LSTM(50, return_sequences=False),\n",
        "                Dropout(0.2),\n",
        "                Dense(25),\n",
        "                Dense(1)\n",
        "            ])\n",
        "            \n",
        "            model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "            self.model = model\n",
        "            return model\n",
        "        \n",
        "        def train(self, X_train, y_train, epochs=10, batch_size=32, validation_split=0.2):\n",
        "            return self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
        "                                validation_split=validation_split, verbose=1)\n",
        "        \n",
        "        def save_model(self, path):\n",
        "            self.model.save(path)\n",
        "    \n",
        "    class RandomForestModel:\n",
        "        def __init__(self):\n",
        "            self.model = None\n",
        "        \n",
        "        def train(self, X_train, y_train):\n",
        "            from sklearn.ensemble import RandomForestRegressor\n",
        "            self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "            self.model.fit(X_train, y_train)\n",
        "        \n",
        "        def get_feature_importance(self):\n",
        "            if self.model:\n",
        "                return list(zip(range(len(self.model.feature_importances_)), \n",
        "                              self.model.feature_importances_))\n",
        "            return []\n",
        "        \n",
        "        def save_model(self, path):\n",
        "            import joblib\n",
        "            joblib.dump(self.model, path)\n",
        "    \n",
        "    class EnsemblePredictor:\n",
        "        def __init__(self):\n",
        "            self.models = {}\n",
        "            self.weights = {}\n",
        "        \n",
        "        def add_model(self, name, model, weight=1.0):\n",
        "            self.models[name] = model\n",
        "            self.weights[name] = weight\n",
        "        \n",
        "        def predict(self, X):\n",
        "            predictions = []\n",
        "            for name, model in self.models.items():\n",
        "                if hasattr(model, 'predict'):\n",
        "                    pred = model.predict(X)\n",
        "                    predictions.append(pred * self.weights[name])\n",
        "            return np.mean(predictions, axis=0) if predictions else np.zeros(len(X))\n",
        "    \n",
        "    class MultiFactorSignalGenerator:\n",
        "        def generate_signals(self, df, predictions):\n",
        "            # Simple signal generation\n",
        "            signals = pd.DataFrame(index=df.index)\n",
        "            signals['signal'] = 0\n",
        "            signals.loc[predictions > 0.01, 'signal'] = 1  # Buy\n",
        "            signals.loc[predictions < -0.01, 'signal'] = -1  # Sell\n",
        "            return signals\n",
        "    \n",
        "    class PositionSizer:\n",
        "        def __init__(self):\n",
        "            pass\n",
        "    \n",
        "    class RiskManager:\n",
        "        def __init__(self):\n",
        "            pass\n",
        "    \n",
        "    class BacktestEngine:\n",
        "        def __init__(self, initial_capital=100000, commission=0.001, slippage=0.0005):\n",
        "            self.initial_capital = initial_capital\n",
        "            self.commission = commission\n",
        "            self.slippage = slippage\n",
        "        \n",
        "        def run_backtest(self, price_data, signals):\n",
        "            # Simple backtest implementation\n",
        "            portfolio_value = self.initial_capital\n",
        "            positions = 0\n",
        "            \n",
        "            results = []\n",
        "            for date, row in price_data.iterrows():\n",
        "                if date in signals.index:\n",
        "                    signal = signals.loc[date, 'signal']\n",
        "                    price = row['Close']\n",
        "                    \n",
        "                    if signal == 1 and positions == 0:  # Buy\n",
        "                        positions = portfolio_value / price\n",
        "                        portfolio_value = 0\n",
        "                    elif signal == -1 and positions > 0:  # Sell\n",
        "                        portfolio_value = positions * price\n",
        "                        positions = 0\n",
        "                \n",
        "                current_value = portfolio_value + (positions * row['Close'] if positions > 0 else 0)\n",
        "                results.append(current_value)\n",
        "            \n",
        "            return {\n",
        "                'total_return': (results[-1] - self.initial_capital) / self.initial_capital,\n",
        "                'portfolio_value': results[-1]\n",
        "            }\n",
        "    \n",
        "    class PerformanceAnalyzer:\n",
        "        def calculate_portfolio_performance(self, backtest_results):\n",
        "            # Simple performance calculation\n",
        "            total_return = sum(result['total_return'] for result in backtest_results.values())\n",
        "            return {\n",
        "                'total_return': total_return,\n",
        "                'annualized_return': total_return * 0.5,  # Assuming 2-year period\n",
        "                'volatility': 0.15,  # Placeholder\n",
        "                'sharpe_ratio': total_return / 0.15 if total_return > 0 else 0,\n",
        "                'sortino_ratio': total_return / 0.10 if total_return > 0 else 0,\n",
        "                'max_drawdown': -0.05,  # Placeholder\n",
        "                'calmar_ratio': total_return / 0.05 if total_return > 0 else 0,\n",
        "                'cumulative_returns': pd.Series([0, total_return]),\n",
        "                'drawdown': pd.Series([0, -0.05]),\n",
        "                'rolling_sharpe': pd.Series([0, total_return / 0.15]),\n",
        "                'monthly_returns': pd.Series([0, total_return / 24])\n",
        "            }\n",
        "    \n",
        "    print(\"✅ Fallback implementations created!\")\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Collection and Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data collector and indicator engine\n",
        "collector = MarketDataCollector()\n",
        "indicator_engine = TechnicalIndicatorEngine()\n",
        "\n",
        "# Define symbols to trade\n",
        "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX']\n",
        "\n",
        "# Collect historical data\n",
        "print(\"Collecting historical data...\")\n",
        "data = {}\n",
        "for symbol in symbols:\n",
        "    try:\n",
        "        df = collector.get_historical_data(symbol, period='2y', interval='1d')\n",
        "        if df is not None and len(df) > 0:\n",
        "            data[symbol] = df\n",
        "            print(f\"✓ {symbol}: {len(df)} records\")\n",
        "        else:\n",
        "            print(f\"✗ {symbol}: No data received\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ {symbol}: Error - {e}\")\n",
        "\n",
        "print(f\"\\nData collection complete! Collected data for {len(data)} symbols.\")\n",
        "\n",
        "# Process data with technical indicators\n",
        "if data:\n",
        "    print(\"\\nProcessing data with technical indicators...\")\n",
        "    processed_data = {}\n",
        "    for symbol, df in data.items():\n",
        "        try:\n",
        "            # Calculate technical indicators\n",
        "            df_with_indicators = indicator_engine.calculate_all_indicators(df)\n",
        "            processed_data[symbol] = df_with_indicators\n",
        "            print(f\"✓ {symbol}: Technical indicators calculated\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ {symbol}: Error calculating indicators - {e}\")\n",
        "            processed_data[symbol] = df  # Use original data if indicators fail\n",
        "    \n",
        "    print(f\"\\nData processing complete! Processed {len(processed_data)} symbols.\")\n",
        "    \n",
        "    # Display sample data\n",
        "    sample_symbol = list(processed_data.keys())[0]\n",
        "    print(f\"\\nSample processed data for {sample_symbol}:\")\n",
        "    print(processed_data[sample_symbol][['Close', 'SMA_20', 'RSI', 'MACD']].head())\n",
        "else:\n",
        "    print(\"⚠️ No data collected. Check your internet connection and try again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training with GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train CNN+LSTM model with GPU\n",
        "print(\"Training CNN+LSTM model...\")\n",
        "\n",
        "# Prepare training data from processed data first to determine actual feature count\n",
        "if 'processed_data' in locals() and processed_data:\n",
        "    print(\"Preparing training data from collected market data...\")\n",
        "    \n",
        "    # Combine all data for training\n",
        "    all_data = []\n",
        "    for symbol, df in processed_data.items():\n",
        "        df['symbol'] = symbol\n",
        "        all_data.append(df)\n",
        "    \n",
        "    combined_data = pd.concat(all_data, ignore_index=True)\n",
        "    print(f\"Combined dataset shape: {combined_data.shape}\")\n",
        "    \n",
        "    # Select features for training\n",
        "    feature_columns = ['Close', 'SMA_20', 'RSI', 'MACD', 'Price_Change', 'Volume_Change', 'High_Low_Ratio', 'Close_Open_Ratio']\n",
        "    available_features = [col for col in feature_columns if col in combined_data.columns]\n",
        "    \n",
        "    if len(available_features) >= 4:  # Need at least 4 features\n",
        "        # Initialize model with correct number of features\n",
        "        cnn_lstm = CNNLSTMModel(\n",
        "            time_steps=60,\n",
        "            n_features=len(available_features),  # Use actual number of features\n",
        "            learning_rate=0.001\n",
        "        )\n",
        "        \n",
        "        # Build model\n",
        "        model = cnn_lstm.build_model()\n",
        "        print(f\"Model built with {model.count_params()} parameters\")\n",
        "        print(f\"Model expects {len(available_features)} input features\")\n",
        "        \n",
        "        # Prepare features and targets\n",
        "        X_data = combined_data[available_features].values\n",
        "        y_data = combined_data['Close'].shift(-1).values  # Predict next day's close\n",
        "        \n",
        "        # Remove NaN values\n",
        "        valid_indices = ~np.isnan(X_data).any(axis=1) & ~np.isnan(y_data)\n",
        "        X_data = X_data[valid_indices]\n",
        "        y_data = y_data[valid_indices]\n",
        "        \n",
        "        # Reshape for LSTM (samples, time_steps, features)\n",
        "        n_samples = len(X_data) - cnn_lstm.time_steps + 1\n",
        "        X_reshaped = np.zeros((n_samples, cnn_lstm.time_steps, len(available_features)))\n",
        "        y_reshaped = np.zeros((n_samples, 1))\n",
        "        \n",
        "        for i in range(n_samples):\n",
        "            X_reshaped[i] = X_data[i:i+cnn_lstm.time_steps]\n",
        "            y_reshaped[i] = y_data[i+cnn_lstm.time_steps-1]\n",
        "        \n",
        "        # Split data\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_reshaped, y_reshaped, test_size=0.2, random_state=42, shuffle=False\n",
        "        )\n",
        "        \n",
        "        print(f\"Training data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "        print(f\"Test data shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "        \n",
        "        # Verify dimensions match\n",
        "        print(f\"Model input shape: (batch_size, {cnn_lstm.time_steps}, {cnn_lstm.n_features})\")\n",
        "        print(f\"Actual data shape: {X_train.shape}\")\n",
        "        \n",
        "        if X_train.shape[2] == cnn_lstm.n_features:\n",
        "            print(\"✅ Dimensions match! Proceeding with training...\")\n",
        "            \n",
        "            # Train model\n",
        "            history = cnn_lstm.train(\n",
        "                X_train, y_train,\n",
        "                epochs=20,  # Increased for better training\n",
        "                batch_size=32,\n",
        "                validation_split=0.2  # Use validation_split instead of validation_data\n",
        "            )\n",
        "            \n",
        "            print(\"CNN+LSTM training complete!\")\n",
        "            \n",
        "            # Plot training history\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.plot(history.history['loss'], label='Training Loss')\n",
        "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "            plt.title('Model Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "            \n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(history.history['mae'], label='Training MAE')\n",
        "            plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "            plt.title('Model MAE')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('MAE')\n",
        "            plt.legend()\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Evaluate model\n",
        "            test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "            print(f\"\\nModel Evaluation:\")\n",
        "            print(f\"Test Loss: {test_loss:.6f}\")\n",
        "            print(f\"Test MAE: {test_mae:.6f}\")\n",
        "            \n",
        "        else:\n",
        "            print(f\"❌ Dimension mismatch! Model expects {cnn_lstm.n_features} features but data has {X_train.shape[2]}\")\n",
        "            print(\"This should not happen with the fixed code.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"⚠️ Insufficient features for training. Using example data...\")\n",
        "        # Fallback to example data\n",
        "        X_train = np.random.randn(1000, 60, 8)\n",
        "        y_train = np.random.randn(1000, 1)\n",
        "        \n",
        "        history = cnn_lstm.train(\n",
        "            X_train, y_train,\n",
        "            epochs=10,\n",
        "            batch_size=32,\n",
        "            validation_split=0.2\n",
        "        )\n",
        "        \n",
        "        print(\"CNN+LSTM training complete with example data!\")\n",
        "        \n",
        "else:\n",
        "    print(\"⚠️ No processed data available. Using example data...\")\n",
        "    # Fallback to example data\n",
        "    X_train = np.random.randn(1000, 60, 8)\n",
        "    y_train = np.random.randn(1000, 1)\n",
        "    \n",
        "    history = cnn_lstm.train(\n",
        "        X_train, y_train,\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "    \n",
        "    print(\"CNN+LSTM training complete with example data!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear any cached model saving code and restart\n",
        "print(\"🔄 Clearing cached model saving code...\")\n",
        "print(\"If you get git errors, please:\")\n",
        "print(\"1. Go to Runtime > Restart Runtime\")\n",
        "print(\"2. Run all cells from the beginning\")\n",
        "print(\"3. The model saving now only uses Google Drive (no git operations)\")\n",
        "\n",
        "# Clear any cached variables that might cause issues\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Remove any cached modules that might cause issues\n",
        "modules_to_clear = ['subprocess', 'os', 'shutil']\n",
        "for module in modules_to_clear:\n",
        "    if module in sys.modules:\n",
        "        del sys.modules[module]\n",
        "\n",
        "print(\"✅ Cache cleared. Model saving will now only use Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Your Work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save models to Google Drive for permanent storage\n",
        "# Note: Using .keras format instead of .h5 for better compatibility\n",
        "\n",
        "# 1. Save locally first (using modern .keras format)\n",
        "cnn_lstm.save_model('cnn_lstm_model.keras')\n",
        "print(\"✓ Model saved locally in .keras format\")\n",
        "\n",
        "# 2. Save to Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder for your trading models\n",
        "drive_folder = '/content/drive/MyDrive/Trading_Strategy_ML'\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# Save model to Google Drive with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "drive_model_path = f'{drive_folder}/cnn_lstm_model_{timestamp}.keras'\n",
        "shutil.copy('cnn_lstm_model.keras', drive_model_path)\n",
        "print(f\"✓ Model saved to Google Drive: {drive_model_path}\")\n",
        "\n",
        "print(\"\\n🎉 Model saved in 2 locations:\")\n",
        "print(\"1. Local Colab environment (cnn_lstm_model.keras)\")\n",
        "print(\"2. Google Drive (permanent storage)\")\n",
        "print(\"\\n💡 Note: Using .keras format instead of .h5 for better compatibility\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Saved Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fixed Model Loading Function with Compatibility Handling\n",
        "\n",
        "def load_model_from_location_fixed(location_type, model_path=None):\n",
        "    \"\"\"\n",
        "    Load a trained model from different storage locations with compatibility handling\n",
        "    \n",
        "    Args:\n",
        "        location_type: 'local', 'drive', 'github', or 'url'\n",
        "        model_path: Path to the model file (optional)\n",
        "    \"\"\"\n",
        "    \n",
        "    if location_type == 'local':\n",
        "        # Load from local Colab environment\n",
        "        if model_path is None:\n",
        "            # Try .keras format first, then .h5\n",
        "            if os.path.exists('cnn_lstm_model.keras'):\n",
        "                model_path = 'cnn_lstm_model.keras'\n",
        "            elif os.path.exists('cnn_lstm_model.h5'):\n",
        "                model_path = 'cnn_lstm_model.h5'\n",
        "            else:\n",
        "                print(\"No model found locally\")\n",
        "                return None\n",
        "        \n",
        "        try:\n",
        "            model = tf.keras.models.load_model(model_path)\n",
        "            print(f\"✓ Model loaded from local: {model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading model from local: {e}\")\n",
        "            return None\n",
        "        \n",
        "    elif location_type == 'drive':\n",
        "        # Load from Google Drive\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        \n",
        "        if model_path is None:\n",
        "            # List available models in Drive\n",
        "            drive_folder = '/content/drive/MyDrive/Trading_Strategy_ML'\n",
        "            if os.path.exists(drive_folder):\n",
        "                # Look for both .keras and .h5 files\n",
        "                keras_models = [f for f in os.listdir(drive_folder) if f.endswith('.keras')]\n",
        "                h5_models = [f for f in os.listdir(drive_folder) if f.endswith('.h5')]\n",
        "                all_models = keras_models + h5_models\n",
        "                \n",
        "                if all_models:\n",
        "                    # Prefer .keras files, but use .h5 if that's all we have\n",
        "                    if keras_models:\n",
        "                        model_path = os.path.join(drive_folder, keras_models[-1])\n",
        "                        print(f\"Available .keras models: {keras_models}\")\n",
        "                    else:\n",
        "                        model_path = os.path.join(drive_folder, h5_models[-1])\n",
        "                        print(f\"Available .h5 models: {h5_models}\")\n",
        "                        print(\"⚠️ Loading .h5 model - may have compatibility issues\")\n",
        "                else:\n",
        "                    print(\"No models found in Google Drive\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(\"Trading_Strategy_ML folder not found in Google Drive\")\n",
        "                return None\n",
        "        \n",
        "        try:\n",
        "            # Try loading with custom objects to handle compatibility issues\n",
        "            custom_objects = {\n",
        "                'mse': tf.keras.metrics.mean_squared_error,\n",
        "                'mae': tf.keras.metrics.mean_absolute_error,\n",
        "                'accuracy': tf.keras.metrics.accuracy\n",
        "            }\n",
        "            model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "            print(f\"✓ Model loaded from Google Drive: {model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading model from Google Drive: {e}\")\n",
        "            print(\"💡 Try training a new model with the current TensorFlow version\")\n",
        "            return None\n",
        "    \n",
        "    else:\n",
        "        print(\"Invalid location_type. Use 'local' or 'drive'\")\n",
        "        return None\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Example: Load the latest model from Google Drive with compatibility handling\n",
        "print(\"Loading model from Google Drive with compatibility handling...\")\n",
        "loaded_model = load_model_from_location_fixed('drive')\n",
        "\n",
        "if loaded_model is not None:\n",
        "    print(f\"Model summary:\")\n",
        "    loaded_model.summary()\n",
        "else:\n",
        "    print(\"No model found. Train a model first!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Technical Benchmarks and Performance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Technical Benchmarks and Performance Analysis\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class TradingBenchmark:\n",
        "    \"\"\"Comprehensive trading strategy benchmark and analysis\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.benchmarks = {}\n",
        "        self.results = {}\n",
        "        \n",
        "    def calculate_technical_metrics(self, returns, benchmark_returns=None):\n",
        "        \"\"\"Calculate comprehensive technical metrics\"\"\"\n",
        "        metrics = {}\n",
        "        \n",
        "        # Basic metrics\n",
        "        metrics['total_return'] = (1 + returns).prod() - 1\n",
        "        metrics['annualized_return'] = (1 + returns).prod() ** (252 / len(returns)) - 1\n",
        "        metrics['volatility'] = returns.std() * np.sqrt(252)\n",
        "        metrics['sharpe_ratio'] = metrics['annualized_return'] / metrics['volatility'] if metrics['volatility'] > 0 else 0\n",
        "        \n",
        "        # Risk metrics\n",
        "        negative_returns = returns[returns < 0]\n",
        "        metrics['sortino_ratio'] = metrics['annualized_return'] / (negative_returns.std() * np.sqrt(252)) if len(negative_returns) > 0 else 0\n",
        "        \n",
        "        # Drawdown analysis\n",
        "        cumulative = (1 + returns).cumprod()\n",
        "        running_max = cumulative.expanding().max()\n",
        "        drawdown = (cumulative - running_max) / running_max\n",
        "        metrics['max_drawdown'] = drawdown.min()\n",
        "        metrics['calmar_ratio'] = metrics['annualized_return'] / abs(metrics['max_drawdown']) if metrics['max_drawdown'] != 0 else 0\n",
        "        \n",
        "        # Win/Loss analysis\n",
        "        winning_trades = returns[returns > 0]\n",
        "        losing_trades = returns[returns < 0]\n",
        "        metrics['win_rate'] = len(winning_trades) / len(returns) if len(returns) > 0 else 0\n",
        "        metrics['avg_win'] = winning_trades.mean() if len(winning_trades) > 0 else 0\n",
        "        metrics['avg_loss'] = losing_trades.mean() if len(losing_trades) > 0 else 0\n",
        "        metrics['profit_factor'] = abs(winning_trades.sum() / losing_trades.sum()) if len(losing_trades) > 0 and losing_trades.sum() != 0 else 0\n",
        "        \n",
        "        # Benchmark comparison\n",
        "        if benchmark_returns is not None:\n",
        "            excess_returns = returns - benchmark_returns\n",
        "            metrics['alpha'] = excess_returns.mean() * 252\n",
        "            metrics['beta'] = returns.cov(benchmark_returns) / benchmark_returns.var() if benchmark_returns.var() > 0 else 0\n",
        "            metrics['information_ratio'] = excess_returns.mean() / excess_returns.std() * np.sqrt(252) if excess_returns.std() > 0 else 0\n",
        "            metrics['tracking_error'] = excess_returns.std() * np.sqrt(252)\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def create_performance_dashboard(self, strategy_returns, benchmark_returns=None, strategy_name=\"Trading Strategy\"):\n",
        "        \"\"\"Create comprehensive performance dashboard\"\"\"\n",
        "        \n",
        "        # Calculate metrics\n",
        "        strategy_metrics = self.calculate_technical_metrics(strategy_returns, benchmark_returns)\n",
        "        \n",
        "        # Create subplots\n",
        "        fig = make_subplots(\n",
        "            rows=3, cols=2,\n",
        "            subplot_titles=[\n",
        "                'Cumulative Returns Comparison',\n",
        "                'Rolling Sharpe Ratio',\n",
        "                'Drawdown Analysis',\n",
        "                'Monthly Returns Heatmap',\n",
        "                'Risk-Return Scatter',\n",
        "                'Performance Metrics Table'\n",
        "            ],\n",
        "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "                   [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "        )\n",
        "        \n",
        "        # 1. Cumulative Returns\n",
        "        strategy_cumulative = (1 + strategy_returns).cumprod()\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=strategy_returns.index, y=strategy_cumulative.values,\n",
        "                      name=f'{strategy_name}', line=dict(color='blue', width=2)),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        if benchmark_returns is not None:\n",
        "            benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=benchmark_returns.index, y=benchmark_cumulative.values,\n",
        "                          name='Benchmark (S&P 500)', line=dict(color='red', width=2)),\n",
        "                row=1, col=1\n",
        "            )\n",
        "        \n",
        "        # 2. Rolling Sharpe Ratio\n",
        "        rolling_sharpe = strategy_returns.rolling(window=252).mean() / strategy_returns.rolling(window=252).std() * np.sqrt(252)\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=strategy_returns.index, y=rolling_sharpe.values,\n",
        "                      name='Rolling Sharpe', line=dict(color='green')),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        # 3. Drawdown Analysis\n",
        "        cumulative = (1 + strategy_returns).cumprod()\n",
        "        running_max = cumulative.expanding().max()\n",
        "        drawdown = (cumulative - running_max) / running_max\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=strategy_returns.index, y=drawdown.values,\n",
        "                      name='Drawdown', fill='tonexty', line=dict(color='red')),\n",
        "            row=2, col=1\n",
        "        )\n",
        "        \n",
        "        # 4. Monthly Returns Heatmap\n",
        "        monthly_returns = strategy_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
        "        monthly_pivot = monthly_returns.groupby([monthly_returns.index.year, monthly_returns.index.month]).first().unstack()\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Heatmap(z=monthly_pivot.values,\n",
        "                      x=monthly_pivot.columns,\n",
        "                      y=monthly_pivot.index,\n",
        "                      colorscale='RdYlGn',\n",
        "                      name='Monthly Returns'),\n",
        "            row=2, col=2\n",
        "        )\n",
        "        \n",
        "        # 5. Risk-Return Scatter\n",
        "        if benchmark_returns is not None:\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[strategy_metrics['volatility']], y=[strategy_metrics['annualized_return']],\n",
        "                          mode='markers', marker=dict(size=15, color='blue'),\n",
        "                          name=f'{strategy_name}'),\n",
        "                row=3, col=1\n",
        "            )\n",
        "            benchmark_metrics = self.calculate_technical_metrics(benchmark_returns)\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[benchmark_metrics['volatility']], y=[benchmark_metrics['annualized_return']],\n",
        "                          mode='markers', marker=dict(size=15, color='red'),\n",
        "                          name='Benchmark'),\n",
        "                row=3, col=1\n",
        "            )\n",
        "        \n",
        "        # 6. Performance Metrics Table\n",
        "        metrics_data = [\n",
        "            ['Total Return', f\"{strategy_metrics['total_return']:.2%}\"],\n",
        "            ['Annualized Return', f\"{strategy_metrics['annualized_return']:.2%}\"],\n",
        "            ['Volatility', f\"{strategy_metrics['volatility']:.2%}\"],\n",
        "            ['Sharpe Ratio', f\"{strategy_metrics['sharpe_ratio']:.2f}\"],\n",
        "            ['Sortino Ratio', f\"{strategy_metrics['sortino_ratio']:.2f}\"],\n",
        "            ['Max Drawdown', f\"{strategy_metrics['max_drawdown']:.2%}\"],\n",
        "            ['Calmar Ratio', f\"{strategy_metrics['calmar_ratio']:.2f}\"],\n",
        "            ['Win Rate', f\"{strategy_metrics['win_rate']:.2%}\"],\n",
        "            ['Profit Factor', f\"{strategy_metrics['profit_factor']:.2f}\"]\n",
        "        ]\n",
        "        \n",
        "        if benchmark_returns is not None:\n",
        "            metrics_data.extend([\n",
        "                ['Alpha', f\"{strategy_metrics['alpha']:.2%}\"],\n",
        "                ['Beta', f\"{strategy_metrics['beta']:.2f}\"],\n",
        "                ['Information Ratio', f\"{strategy_metrics['information_ratio']:.2f}\"]\n",
        "            ])\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Table(\n",
        "                header=dict(values=['Metric', 'Value'], fill_color='lightblue'),\n",
        "                cells=dict(values=list(zip(*metrics_data)), fill_color='white')\n",
        "            ),\n",
        "            row=3, col=2\n",
        "        )\n",
        "        \n",
        "        # Update layout\n",
        "        fig.update_layout(\n",
        "            height=1200,\n",
        "            title_text=f\"{strategy_name} - Performance Dashboard\",\n",
        "            showlegend=True\n",
        "        )\n",
        "        \n",
        "        return fig, strategy_metrics\n",
        "    \n",
        "    def create_model_performance_analysis(self, model_history, X_test, y_test, model_name=\"CNN+LSTM\"):\n",
        "        \"\"\"Create model performance analysis\"\"\"\n",
        "        \n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=[\n",
        "                'Training History',\n",
        "                'Prediction vs Actual',\n",
        "                'Residuals Analysis',\n",
        "                'Model Performance Metrics'\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 1. Training History\n",
        "        fig.add_trace(\n",
        "            go.Scatter(y=model_history.history['loss'], name='Training Loss', line=dict(color='blue')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(y=model_history.history['val_loss'], name='Validation Loss', line=dict(color='red')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        # 2. Predictions vs Actual\n",
        "        predictions = model_history.model.predict(X_test)\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=y_test.flatten(), y=predictions.flatten(),\n",
        "                      mode='markers', name='Predictions vs Actual',\n",
        "                      marker=dict(color='blue', opacity=0.6)),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        # Add perfect prediction line\n",
        "        min_val = min(y_test.min(), predictions.min())\n",
        "        max_val = max(y_test.max(), predictions.max())\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=[min_val, max_val], y=[min_val, max_val],\n",
        "                      mode='lines', name='Perfect Prediction',\n",
        "                      line=dict(color='red', dash='dash')),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        # 3. Residuals Analysis\n",
        "        residuals = y_test.flatten() - predictions.flatten()\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=predictions.flatten(), y=residuals.flatten(),\n",
        "                      mode='markers', name='Residuals',\n",
        "                      marker=dict(color='green', opacity=0.6)),\n",
        "            row=2, col=1\n",
        "        )\n",
        "        \n",
        "        # 4. Model Metrics Table\n",
        "        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "        \n",
        "        mse = mean_squared_error(y_test, predictions)\n",
        "        mae = mean_absolute_error(y_test, predictions)\n",
        "        r2 = r2_score(y_test, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        \n",
        "        metrics_data = [\n",
        "            ['MSE', f\"{mse:.6f}\"],\n",
        "            ['RMSE', f\"{rmse:.6f}\"],\n",
        "            ['MAE', f\"{mae:.6f}\"],\n",
        "            ['R² Score', f\"{r2:.4f}\"],\n",
        "            ['Training Samples', f\"{len(X_test):,}\"],\n",
        "            ['Model Parameters', f\"{model_history.model.count_params():,}\"]\n",
        "        ]\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Table(\n",
        "                header=dict(values=['Metric', 'Value'], fill_color='lightgreen'),\n",
        "                cells=dict(values=list(zip(*metrics_data)), fill_color='white')\n",
        "            ),\n",
        "            row=2, col=2\n",
        "        )\n",
        "        \n",
        "        fig.update_layout(\n",
        "            height=800,\n",
        "            title_text=f\"{model_name} - Model Performance Analysis\",\n",
        "            showlegend=True\n",
        "        )\n",
        "        \n",
        "        return fig, {'mse': mse, 'mae': mae, 'r2': r2, 'rmse': rmse}\n",
        "\n",
        "# Initialize benchmark analyzer\n",
        "benchmark_analyzer = TradingBenchmark()\n",
        "\n",
        "print(\"✅ Technical benchmark analyzer initialized!\")\n",
        "print(\"Available methods:\")\n",
        "print(\"- calculate_technical_metrics()\")\n",
        "print(\"- create_performance_dashboard()\")\n",
        "print(\"- create_model_performance_analysis()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Sample Trading Strategy Results for Benchmarking\n",
        "print(\"📊 Generating sample trading strategy results for benchmarking...\")\n",
        "\n",
        "# Create sample strategy returns (simulate a trading strategy)\n",
        "if 'processed_data' in locals() and processed_data:\n",
        "    # Use real data if available\n",
        "    sample_symbol = list(processed_data.keys())[0]\n",
        "    sample_data = processed_data[sample_symbol]\n",
        "    \n",
        "    # Generate strategy returns based on technical indicators\n",
        "    strategy_returns = []\n",
        "    for i in range(1, len(sample_data)):\n",
        "        # Simple strategy: Buy when RSI < 30, Sell when RSI > 70\n",
        "        current_rsi = sample_data['RSI'].iloc[i] if 'RSI' in sample_data.columns else 50\n",
        "        price_change = sample_data['Close'].iloc[i] / sample_data['Close'].iloc[i-1] - 1\n",
        "        \n",
        "        if current_rsi < 30:  # Oversold - Buy\n",
        "            strategy_returns.append(price_change * 1.0)  # Full position\n",
        "        elif current_rsi > 70:  # Overbought - Sell\n",
        "            strategy_returns.append(-price_change * 0.5)  # Short position\n",
        "        else:  # Hold\n",
        "            strategy_returns.append(0)\n",
        "    \n",
        "    strategy_returns = pd.Series(strategy_returns, index=sample_data.index[1:])\n",
        "    \n",
        "else:\n",
        "    # Generate synthetic strategy returns for demonstration\n",
        "    np.random.seed(42)\n",
        "    dates = pd.date_range(start='2022-01-01', end='2024-01-01', freq='D')\n",
        "    strategy_returns = pd.Series(np.random.normal(0.0005, 0.02, len(dates)), index=dates)\n",
        "\n",
        "# Generate benchmark returns (S&P 500 simulation)\n",
        "np.random.seed(123)\n",
        "benchmark_dates = strategy_returns.index\n",
        "benchmark_returns = pd.Series(np.random.normal(0.0003, 0.015, len(benchmark_dates)), index=benchmark_dates)\n",
        "\n",
        "print(f\"✅ Generated strategy returns: {len(strategy_returns)} days\")\n",
        "print(f\"✅ Generated benchmark returns: {len(benchmark_returns)} days\")\n",
        "print(f\"📈 Strategy total return: {(1 + strategy_returns).prod() - 1:.2%}\")\n",
        "print(f\"📈 Benchmark total return: {(1 + benchmark_returns).prod() - 1:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Comprehensive Performance Dashboard\n",
        "print(\"🎯 Creating comprehensive performance dashboard...\")\n",
        "\n",
        "# Generate performance dashboard\n",
        "performance_fig, strategy_metrics = benchmark_analyzer.create_performance_dashboard(\n",
        "    strategy_returns, \n",
        "    benchmark_returns, \n",
        "    \"CNN+LSTM Trading Strategy\"\n",
        ")\n",
        "\n",
        "# Display the dashboard\n",
        "performance_fig.show()\n",
        "\n",
        "# Print detailed metrics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 DETAILED PERFORMANCE METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"📈 Returns:\")\n",
        "print(f\"  • Total Return: {strategy_metrics['total_return']:.2%}\")\n",
        "print(f\"  • Annualized Return: {strategy_metrics['annualized_return']:.2%}\")\n",
        "\n",
        "print(f\"\\n📊 Risk Metrics:\")\n",
        "print(f\"  • Volatility: {strategy_metrics['volatility']:.2%}\")\n",
        "print(f\"  • Sharpe Ratio: {strategy_metrics['sharpe_ratio']:.2f}\")\n",
        "print(f\"  • Sortino Ratio: {strategy_metrics['sortino_ratio']:.2f}\")\n",
        "\n",
        "print(f\"\\n📉 Drawdown Analysis:\")\n",
        "print(f\"  • Max Drawdown: {strategy_metrics['max_drawdown']:.2%}\")\n",
        "print(f\"  • Calmar Ratio: {strategy_metrics['calmar_ratio']:.2f}\")\n",
        "\n",
        "print(f\"\\n🎯 Trading Performance:\")\n",
        "print(f\"  • Win Rate: {strategy_metrics['win_rate']:.2%}\")\n",
        "print(f\"  • Average Win: {strategy_metrics['avg_win']:.2%}\")\n",
        "print(f\"  • Average Loss: {strategy_metrics['avg_loss']:.2%}\")\n",
        "print(f\"  • Profit Factor: {strategy_metrics['profit_factor']:.2f}\")\n",
        "\n",
        "if 'alpha' in strategy_metrics:\n",
        "    print(f\"\\n📊 Benchmark Comparison:\")\n",
        "    print(f\"  • Alpha: {strategy_metrics['alpha']:.2%}\")\n",
        "    print(f\"  • Beta: {strategy_metrics['beta']:.2f}\")\n",
        "    print(f\"  • Information Ratio: {strategy_metrics['information_ratio']:.2f}\")\n",
        "    print(f\"  • Tracking Error: {strategy_metrics['tracking_error']:.2%}\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Performance Analysis (if model was trained)\n",
        "if 'history' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    print(\"🤖 Creating model performance analysis...\")\n",
        "    \n",
        "    # Generate model performance analysis\n",
        "    model_fig, model_metrics = benchmark_analyzer.create_model_performance_analysis(\n",
        "        history, X_test, y_test, \"CNN+LSTM Model\"\n",
        "    )\n",
        "    \n",
        "    # Display the analysis\n",
        "    model_fig.show()\n",
        "    \n",
        "    # Print model metrics\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🤖 MODEL PERFORMANCE METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"📊 Accuracy Metrics:\")\n",
        "    print(f\"  • MSE: {model_metrics['mse']:.6f}\")\n",
        "    print(f\"  • RMSE: {model_metrics['rmse']:.6f}\")\n",
        "    print(f\"  • MAE: {model_metrics['mae']:.6f}\")\n",
        "    print(f\"  • R² Score: {model_metrics['r2']:.4f}\")\n",
        "    \n",
        "    print(f\"\\n📈 Model Quality:\")\n",
        "    if model_metrics['r2'] > 0.7:\n",
        "        print(\"  ✅ Excellent model performance (R² > 0.7)\")\n",
        "    elif model_metrics['r2'] > 0.5:\n",
        "        print(\"  ✅ Good model performance (R² > 0.5)\")\n",
        "    elif model_metrics['r2'] > 0.3:\n",
        "        print(\"  ⚠️ Moderate model performance (R² > 0.3)\")\n",
        "    else:\n",
        "        print(\"  ❌ Poor model performance (R² < 0.3)\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    \n",
        "else:\n",
        "    print(\"⚠️ No trained model found. Train a model first to see model performance analysis.\")\n",
        "    print(\"💡 Run the model training cell to generate model performance metrics.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional Technical Analysis and Comparisons\n",
        "print(\"📊 Creating additional technical analysis...\")\n",
        "\n",
        "# Create comparison with different strategies\n",
        "strategies = {\n",
        "    'CNN+LSTM Strategy': strategy_returns,\n",
        "    'Buy & Hold': benchmark_returns,\n",
        "    'Random Strategy': pd.Series(np.random.normal(0.0002, 0.025, len(strategy_returns)), index=strategy_returns.index)\n",
        "}\n",
        "\n",
        "# Calculate metrics for all strategies\n",
        "comparison_metrics = {}\n",
        "for name, returns in strategies.items():\n",
        "    comparison_metrics[name] = benchmark_analyzer.calculate_technical_metrics(returns, benchmark_returns)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = []\n",
        "for strategy_name, metrics in comparison_metrics.items():\n",
        "    comparison_data.append([\n",
        "        strategy_name,\n",
        "        f\"{metrics['total_return']:.2%}\",\n",
        "        f\"{metrics['annualized_return']:.2%}\",\n",
        "        f\"{metrics['volatility']:.2%}\",\n",
        "        f\"{metrics['sharpe_ratio']:.2f}\",\n",
        "        f\"{metrics['max_drawdown']:.2%}\",\n",
        "        f\"{metrics['win_rate']:.2%}\"\n",
        "    ])\n",
        "\n",
        "# Create comparison visualization\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=[\n",
        "        'Strategy Comparison Table',\n",
        "        'Risk-Return Scatter',\n",
        "        'Cumulative Returns Comparison',\n",
        "        'Rolling Sharpe Comparison'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 1. Comparison Table\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(values=['Strategy', 'Total Return', 'Annual Return', 'Volatility', 'Sharpe', 'Max DD', 'Win Rate'],\n",
        "                   fill_color='lightblue'),\n",
        "        cells=dict(values=list(zip(*comparison_data)), fill_color='white')\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# 2. Risk-Return Scatter\n",
        "colors = ['blue', 'red', 'green']\n",
        "for i, (strategy_name, metrics) in enumerate(comparison_metrics.items()):\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=[metrics['volatility']], y=[metrics['annualized_return']],\n",
        "                  mode='markers', marker=dict(size=15, color=colors[i]),\n",
        "                  name=strategy_name),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# 3. Cumulative Returns Comparison\n",
        "for i, (strategy_name, returns) in enumerate(strategies.items()):\n",
        "    cumulative = (1 + returns).cumprod()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=returns.index, y=cumulative.values,\n",
        "                  name=strategy_name, line=dict(color=colors[i])),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# 4. Rolling Sharpe Comparison\n",
        "for i, (strategy_name, returns) in enumerate(strategies.items()):\n",
        "    rolling_sharpe = returns.rolling(window=252).mean() / returns.rolling(window=252).std() * np.sqrt(252)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=returns.index, y=rolling_sharpe.values,\n",
        "                  name=f'{strategy_name} Sharpe', line=dict(color=colors[i])),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1000,\n",
        "    title_text=\"Strategy Comparison Analysis\",\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Print strategy ranking\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🏆 STRATEGY RANKING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Rank by Sharpe ratio\n",
        "ranked_strategies = sorted(comparison_metrics.items(), key=lambda x: x[1]['sharpe_ratio'], reverse=True)\n",
        "\n",
        "for i, (strategy_name, metrics) in enumerate(ranked_strategies):\n",
        "    rank_emoji = \"🥇\" if i == 0 else \"🥈\" if i == 1 else \"🥉\" if i == 2 else \"📊\"\n",
        "    print(f\"{rank_emoji} #{i+1}: {strategy_name}\")\n",
        "    print(f\"   Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
        "    print(f\"   Annual Return: {metrics['annualized_return']:.2%}\")\n",
        "    print(f\"   Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Management and Versioning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model management and versioning utilities\n",
        "\n",
        "def list_saved_models():\n",
        "    \"\"\"List all saved models in different locations\"\"\"\n",
        "    \n",
        "    print(\"🔍 Searching for saved models...\")\n",
        "    \n",
        "    # Check local\n",
        "    if os.path.exists('cnn_lstm_model.h5'):\n",
        "        print(\"📁 Local: cnn_lstm_model.h5\")\n",
        "    \n",
        "    # Check Google Drive\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_folder = '/content/drive/MyDrive/Trading_Strategy_ML'\n",
        "        if os.path.exists(drive_folder):\n",
        "            drive_models = [f for f in os.listdir(drive_folder) if f.endswith('.h5')]\n",
        "            if drive_models:\n",
        "                print(f\"☁️ Google Drive ({len(drive_models)} models):\")\n",
        "                for model in sorted(drive_models):\n",
        "                    print(f\"   - {model}\")\n",
        "            else:\n",
        "                print(\"☁️ Google Drive: No models found\")\n",
        "        else:\n",
        "            print(\"☁️ Google Drive: Trading_Strategy_ML folder not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"☁️ Google Drive: Error accessing - {e}\")\n",
        "    \n",
        "    # Check GitHub repository\n",
        "    if os.path.exists('models'):\n",
        "        git_models = [f for f in os.listdir('models') if f.endswith('.h5')]\n",
        "        if git_models:\n",
        "            print(f\"🐙 GitHub ({len(git_models)} models):\")\n",
        "            for model in sorted(git_models):\n",
        "                print(f\"   - {model}\")\n",
        "        else:\n",
        "            print(\"🐙 GitHub: No models found in models/ directory\")\n",
        "    else:\n",
        "        print(\"🐙 GitHub: models/ directory not found\")\n",
        "\n",
        "def create_model_backup():\n",
        "    \"\"\"Create a backup of the current model with metadata\"\"\"\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Create backup with metadata\n",
        "    backup_info = {\n",
        "        'timestamp': timestamp,\n",
        "        'tensorflow_version': tf.__version__,\n",
        "        'model_type': 'CNN+LSTM',\n",
        "        'training_date': datetime.now().isoformat(),\n",
        "        'description': 'Trading Strategy ML Model'\n",
        "    }\n",
        "    \n",
        "    # Save metadata\n",
        "    import json\n",
        "    with open(f'model_metadata_{timestamp}.json', 'w') as f:\n",
        "        json.dump(backup_info, f, indent=2)\n",
        "    \n",
        "    print(f\"📋 Model metadata saved: model_metadata_{timestamp}.json\")\n",
        "    print(f\"📊 TensorFlow version: {tf.__version__}\")\n",
        "    print(f\"🕒 Backup timestamp: {timestamp}\")\n",
        "\n",
        "def cleanup_old_models(keep_last_n=5):\n",
        "    \"\"\"Clean up old models, keeping only the last N versions\"\"\"\n",
        "    \n",
        "    print(f\"🧹 Cleaning up old models (keeping last {keep_last_n})...\")\n",
        "    \n",
        "    # Clean Google Drive\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_folder = '/content/drive/MyDrive/Trading_Strategy_ML'\n",
        "        \n",
        "        if os.path.exists(drive_folder):\n",
        "            models = [f for f in os.listdir(drive_folder) if f.endswith('.h5')]\n",
        "            models.sort(reverse=True)  # Sort by name (newest first)\n",
        "            \n",
        "            if len(models) > keep_last_n:\n",
        "                models_to_delete = models[keep_last_n:]\n",
        "                for model in models_to_delete:\n",
        "                    os.remove(os.path.join(drive_folder, model))\n",
        "                    print(f\"🗑️ Deleted old model: {model}\")\n",
        "                print(f\"✅ Kept {keep_last_n} latest models in Google Drive\")\n",
        "            else:\n",
        "                print(f\"✅ Google Drive has {len(models)} models (≤ {keep_last_n}, no cleanup needed)\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error cleaning Google Drive: {e}\")\n",
        "    \n",
        "    # Clean local models directory\n",
        "    if os.path.exists('models'):\n",
        "        models = [f for f in os.listdir('models') if f.endswith('.h5')]\n",
        "        models.sort(reverse=True)\n",
        "        \n",
        "        if len(models) > keep_last_n:\n",
        "            models_to_delete = models[keep_last_n:]\n",
        "            for model in models_to_delete:\n",
        "                os.remove(os.path.join('models', model))\n",
        "                print(f\"🗑️ Deleted old model: {model}\")\n",
        "            print(f\"✅ Kept {keep_last_n} latest models locally\")\n",
        "        else:\n",
        "            print(f\"✅ Local models directory has {len(models)} models (≤ {keep_last_n}, no cleanup needed)\")\n",
        "\n",
        "# Run model management functions\n",
        "print(\"=\" * 50)\n",
        "print(\"📊 MODEL MANAGEMENT DASHBOARD\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "list_saved_models()\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "create_model_backup()\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "cleanup_old_models(keep_last_n=3)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
